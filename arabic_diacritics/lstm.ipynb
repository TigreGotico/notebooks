{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic Diacritization Model\n",
    "This notebook trains a small model to predict Arabic diacritics, exports to ONNX, and benchmarks performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:55:57.087070Z",
     "iopub.status.busy": "2026-02-13T18:55:57.086608Z",
     "iopub.status.idle": "2026-02-13T18:56:01.590574Z",
     "shell.execute_reply": "2026-02-13T18:56:01.589553Z",
     "shell.execute_reply.started": "2026-02-13T18:55:57.087039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.20.1)\n",
      "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.24.1)\n",
      "Requirement already satisfied: pyarabic in /usr/local/lib/python3.11/dist-packages (0.6.15)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.3)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (6.33.5)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.9.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from onnx) (0.5.4)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (23.5.26)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (23.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from pyarabic) (1.16.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu --break-system-packages\n",
    "!pip install onnx onnxruntime pyarabic --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:56:01.834558Z",
     "iopub.status.busy": "2026-02-13T18:56:01.834172Z",
     "iopub.status.idle": "2026-02-13T18:56:06.683561Z",
     "shell.execute_reply": "2026-02-13T18:56:06.682593Z",
     "shell.execute_reply.started": "2026-02-13T18:56:01.834518Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from collections import Counter\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Download dataset: https://huggingface.co/datasets/TigreGotico/arabic_diacritized_text"
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:56:01.592680Z",
     "iopub.status.busy": "2026-02-13T18:56:01.592421Z",
     "iopub.status.idle": "2026-02-13T18:56:01.832453Z",
     "shell.execute_reply": "2026-02-13T18:56:01.831151Z",
     "shell.execute_reply.started": "2026-02-13T18:56:01.592656Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt  train.txt  val.txt\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": "!ls /datasets/arabic-diacritics"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:56:06.685158Z",
     "iopub.status.busy": "2026-02-13T18:56:06.684827Z",
     "iopub.status.idle": "2026-02-13T18:56:06.750928Z",
     "shell.execute_reply": "2026-02-13T18:56:06.750036Z",
     "shell.execute_reply.started": "2026-02-13T18:56:06.685134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "TRAIN_FILE = '/datasets/arabic-diacritics/train.txt'  # Training data file\n",
    "VAL_FILE = '/datasets/arabic-diacritics/val.txt'      # Validation data file\n",
    "TEST_FILE = '/datasets/arabic-diacritics/test.txt'    # Test data file\n",
    "MODEL_PATH = 'diacritization_model.pth'\n",
    "ONNX_PATH = 'diacritization_model.onnx'\n",
    "\n",
    "# Model hyperparameters\n",
    "EMBEDDING_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "MAX_SEQ_LENGTH = 100\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Arabic Diacritics Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:56:06.753260Z",
     "iopub.status.busy": "2026-02-13T18:56:06.753019Z",
     "iopub.status.idle": "2026-02-13T18:56:06.761808Z",
     "shell.execute_reply": "2026-02-13T18:56:06.760394Z",
     "shell.execute_reply.started": "2026-02-13T18:56:06.753236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diacritics defined: ['َ', 'ً', 'ُ', 'ٌ', 'ِ', 'ٍ', 'ْ', 'ّ']\n"
     ]
    }
   ],
   "source": [
    "# Arabic diacritics\n",
    "ARABIC_DIACRITICS = {\n",
    "    'َ': 'FATHA',           # Fatha\n",
    "    'ً': 'TANWIN_FATH',    # Tanwin Fath\n",
    "    'ُ': 'DAMMA',           # Damma\n",
    "    'ٌ': 'TANWIN_DAMM',    # Tanwin Damm\n",
    "    'ِ': 'KASRA',           # Kasra\n",
    "    'ٍ': 'TANWIN_KASR',    # Tanwin Kasr\n",
    "    'ْ': 'SUKUN',           # Sukun\n",
    "    'ّ': 'SHADDA',          # Shadda\n",
    "}\n",
    "\n",
    "DIACRITIC_CHARS = ''.join(ARABIC_DIACRITICS.keys())\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    \"\"\"Remove all Arabic diacritics from text\"\"\"\n",
    "    return re.sub(f'[{DIACRITIC_CHARS}]', '', text)\n",
    "\n",
    "def extract_diacritics(text):\n",
    "    \"\"\"Extract diacritics aligned with characters\"\"\"\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        char = text[i]\n",
    "        if char in DIACRITIC_CHARS:\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Collect diacritics after this character\n",
    "        diacritics = []\n",
    "        j = i + 1\n",
    "        while j < len(text) and text[j] in DIACRITIC_CHARS:\n",
    "            diacritics.append(text[j])\n",
    "            j += 1\n",
    "        \n",
    "        # Store character and its diacritics\n",
    "        result.append((char, ''.join(diacritics)))\n",
    "        i = j\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"Diacritics defined:\", list(ARABIC_DIACRITICS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:56:06.763042Z",
     "iopub.status.busy": "2026-02-13T18:56:06.762814Z",
     "iopub.status.idle": "2026-02-13T18:56:48.730110Z",
     "shell.execute_reply": "2026-02-13T18:56:48.729437Z",
     "shell.execute_reply.started": "2026-02-13T18:56:06.763019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loaded 150000 training sentences\n",
      "Loaded 150000 validation sentences\n",
      "Loaded 150000 test sentences\n",
      "\n",
      "Sample training sentence: مُنَاوِيٌّ .( 6 / 155 )...\n",
      "\n",
      "Created 150000 training pairs\n",
      "Created 150000 validation pairs\n",
      "Created 150000 test pairs\n",
      "\n",
      "Example:\n",
      "Undiacritized: مناوي .( 6 / 155 )\n",
      "Diacritized: مُنَاوِيٌّ .( 6 / 155 )\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def load_sentences(file_path):\n",
    "    \"\"\"Load sentences from a file\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    random.shuffle(sentences)\n",
    "    return sentences[:150000]\n",
    "\n",
    "# Load all datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_sentences = load_sentences(TRAIN_FILE)\n",
    "val_sentences = load_sentences(VAL_FILE)\n",
    "test_sentences = load_sentences(TEST_FILE)\n",
    "\n",
    "print(f\"Loaded {len(train_sentences)} training sentences\")\n",
    "print(f\"Loaded {len(val_sentences)} validation sentences\")\n",
    "print(f\"Loaded {len(test_sentences)} test sentences\")\n",
    "print(f\"\\nSample training sentence: {train_sentences[0][:100]}...\")\n",
    "\n",
    "# Create paired dataset function\n",
    "def create_paired_data(sentences):\n",
    "    \"\"\"Convert sentences to paired undiacritized/diacritized format\"\"\"\n",
    "    paired_data = []\n",
    "    for sentence in sentences:\n",
    "        undiacritized = remove_diacritics(sentence)\n",
    "        char_diac_pairs = extract_diacritics(sentence)\n",
    "        \n",
    "        if len(undiacritized) > 0 and len(char_diac_pairs) > 0:\n",
    "            paired_data.append({\n",
    "                'undiacritized': undiacritized,\n",
    "                'diacritized': sentence,\n",
    "                'char_diac_pairs': char_diac_pairs\n",
    "            })\n",
    "    return paired_data\n",
    "\n",
    "# Create paired datasets\n",
    "train_paired_data = create_paired_data(train_sentences)\n",
    "val_paired_data = create_paired_data(val_sentences)\n",
    "test_paired_data = create_paired_data(test_sentences)\n",
    "\n",
    "print(f\"\\nCreated {len(train_paired_data)} training pairs\")\n",
    "print(f\"Created {len(val_paired_data)} validation pairs\")\n",
    "print(f\"Created {len(test_paired_data)} test pairs\")\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"Undiacritized: {train_paired_data[0]['undiacritized'][:50]}\")\n",
    "print(f\"Diacritized: {train_paired_data[0]['diacritized'][:50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:56:48.732077Z",
     "iopub.status.busy": "2026-02-13T18:56:48.731406Z",
     "iopub.status.idle": "2026-02-13T18:57:01.498627Z",
     "shell.execute_reply": "2026-02-13T18:57:01.496692Z",
     "shell.execute_reply.started": "2026-02-13T18:56:48.732051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character vocabulary size: 201\n",
      "Diacritic vocabulary size: 28\n",
      "\n",
      "Diacritic classes: ['', 'ً', 'ًّ', 'ٌ', 'ٌّ', 'ٍ', 'ٍّ', 'َ', 'ًَ', 'ََ']...\n"
     ]
    }
   ],
   "source": [
    "# Build character vocabulary from all datasets\n",
    "all_chars = set()\n",
    "for item in train_paired_data + val_paired_data + test_paired_data:\n",
    "    all_chars.update(item['undiacritized'])\n",
    "\n",
    "# Special tokens\n",
    "char_to_idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "for char in sorted(all_chars):\n",
    "    char_to_idx[char] = len(char_to_idx)\n",
    "\n",
    "idx_to_char = {v: k for k, v in char_to_idx.items()}\n",
    "\n",
    "# Build diacritic vocabulary (combinations of diacritics) from all datasets\n",
    "all_diacritics = set()\n",
    "for item in train_paired_data + val_paired_data + test_paired_data:\n",
    "    for _, diacs in item['char_diac_pairs']:\n",
    "        all_diacritics.add(diacs)\n",
    "\n",
    "# Include empty string for no diacritic\n",
    "diac_to_idx = {'': 0}  # No diacritic\n",
    "for diac in sorted(all_diacritics):\n",
    "    if diac:  # Skip empty string as it's already added\n",
    "        diac_to_idx[diac] = len(diac_to_idx)\n",
    "\n",
    "idx_to_diac = {v: k for k, v in diac_to_idx.items()}\n",
    "\n",
    "print(f\"Character vocabulary size: {len(char_to_idx)}\")\n",
    "print(f\"Diacritic vocabulary size: {len(diac_to_idx)}\")\n",
    "print(f\"\\nDiacritic classes: {list(diac_to_idx.keys())[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:57:01.502506Z",
     "iopub.status.busy": "2026-02-13T18:57:01.501473Z",
     "iopub.status.idle": "2026-02-13T18:57:01.526624Z",
     "shell.execute_reply": "2026-02-13T18:57:01.524965Z",
     "shell.execute_reply.started": "2026-02-13T18:57:01.502426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 150000\n",
      "Validation samples: 150000\n",
      "Test samples: 150000\n"
     ]
    }
   ],
   "source": [
    "class ArabicDiacritizationDataset(Dataset):\n",
    "    def __init__(self, paired_data, char_to_idx, diac_to_idx, max_length):\n",
    "        self.data = paired_data\n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.diac_to_idx = diac_to_idx\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Encode characters\n",
    "        chars = item['undiacritized'][:self.max_length]\n",
    "        char_indices = [self.char_to_idx.get(c, self.char_to_idx['<UNK>']) for c in chars]\n",
    "        \n",
    "        # Encode diacritics\n",
    "        diac_indices = []\n",
    "        for char, diacs in item['char_diac_pairs'][:self.max_length]:\n",
    "            diac_idx = self.diac_to_idx.get(diacs, 0)\n",
    "            diac_indices.append(diac_idx)\n",
    "        \n",
    "        # Pad sequences\n",
    "        seq_len = len(char_indices)\n",
    "        char_indices += [0] * (self.max_length - seq_len)\n",
    "        diac_indices += [0] * (self.max_length - seq_len)\n",
    "        \n",
    "        return {\n",
    "            'chars': torch.tensor(char_indices, dtype=torch.long),\n",
    "            'diacritics': torch.tensor(diac_indices, dtype=torch.long),\n",
    "            'length': seq_len\n",
    "        }\n",
    "\n",
    "# Create datasets from the separate files\n",
    "train_dataset = ArabicDiacritizationDataset(train_paired_data, char_to_idx, diac_to_idx, MAX_SEQ_LENGTH)\n",
    "val_dataset = ArabicDiacritizationDataset(val_paired_data, char_to_idx, diac_to_idx, MAX_SEQ_LENGTH)\n",
    "test_dataset = ArabicDiacritizationDataset(test_paired_data, char_to_idx, diac_to_idx, MAX_SEQ_LENGTH)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:57:01.531520Z",
     "iopub.status.busy": "2026-02-13T18:57:01.528902Z",
     "iopub.status.idle": "2026-02-13T18:57:02.191708Z",
     "shell.execute_reply": "2026-02-13T18:57:02.190848Z",
     "shell.execute_reply.started": "2026-02-13T18:57:01.531379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiacritizationModel(\n",
      "  (embedding): Embedding(201, 64, padding_idx=0)\n",
      "  (lstm): LSTM(64, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=28, bias=True)\n",
      ")\n",
      "\n",
      "Total parameters: 613,980\n"
     ]
    }
   ],
   "source": [
    "class DiacritizationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, diac_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(DiacritizationModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, diac_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len)\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        lstm_out, _ = self.lstm(embedded)  # (batch, seq_len, hidden_dim*2)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        output = self.fc(lstm_out)  # (batch, seq_len, diac_size)\n",
    "        return output\n",
    "\n",
    "model = DiacritizationModel(\n",
    "    vocab_size=len(char_to_idx),\n",
    "    diac_size=len(diac_to_idx),\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:57:02.193358Z",
     "iopub.status.busy": "2026-02-13T18:57:02.192591Z",
     "iopub.status.idle": "2026-02-13T19:10:33.761323Z",
     "shell.execute_reply": "2026-02-13T19:10:33.760447Z",
     "shell.execute_reply.started": "2026-02-13T18:57:02.193334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/10\n",
      "  Train Loss: 0.3882, Train Acc: 0.8679\n",
      "  Val Loss: 0.2259, Val Acc: 0.9238\n",
      "\n",
      "Epoch 2/10\n",
      "  Train Loss: 0.2093, Train Acc: 0.9298\n",
      "  Val Loss: 0.1796, Val Acc: 0.9393\n",
      "\n",
      "Epoch 3/10\n",
      "  Train Loss: 0.1738, Train Acc: 0.9417\n",
      "  Val Loss: 0.1632, Val Acc: 0.9449\n",
      "\n",
      "Epoch 4/10\n",
      "  Train Loss: 0.1551, Train Acc: 0.9479\n",
      "  Val Loss: 0.1501, Val Acc: 0.9496\n",
      "\n",
      "Epoch 5/10\n",
      "  Train Loss: 0.1431, Train Acc: 0.9519\n",
      "  Val Loss: 0.1440, Val Acc: 0.9521\n",
      "\n",
      "Epoch 6/10\n",
      "  Train Loss: 0.1340, Train Acc: 0.9548\n",
      "  Val Loss: 0.1390, Val Acc: 0.9534\n",
      "\n",
      "Epoch 7/10\n",
      "  Train Loss: 0.1270, Train Acc: 0.9571\n",
      "  Val Loss: 0.1364, Val Acc: 0.9546\n",
      "\n",
      "Epoch 8/10\n",
      "  Train Loss: 0.1215, Train Acc: 0.9588\n",
      "  Val Loss: 0.1340, Val Acc: 0.9554\n",
      "\n",
      "Epoch 9/10\n",
      "  Train Loss: 0.1167, Train Acc: 0.9604\n",
      "  Val Loss: 0.1338, Val Acc: 0.9560\n",
      "\n",
      "Epoch 10/10\n",
      "  Train Loss: 0.1126, Train Acc: 0.9618\n",
      "  Val Loss: 0.1325, Val Acc: 0.9567\n",
      "\n",
      "Model saved to diacritization_model.pth\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        chars = batch['chars'].to(device)\n",
    "        diacritics = batch['diacritics'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(chars)\n",
    "        \n",
    "        # Reshape for loss calculation\n",
    "        outputs = outputs.view(-1, outputs.size(-1))\n",
    "        diacritics = diacritics.view(-1)\n",
    "        \n",
    "        loss = criterion(outputs, diacritics)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "        mask = diacritics != 0\n",
    "        correct += (predictions[mask] == diacritics[mask]).sum().item()\n",
    "        total += mask.sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), correct / total if total > 0 else 0\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            chars = batch['chars'].to(device)\n",
    "            diacritics = batch['diacritics'].to(device)\n",
    "            \n",
    "            outputs = model(chars)\n",
    "            \n",
    "            outputs_flat = outputs.view(-1, outputs.size(-1))\n",
    "            diacritics_flat = diacritics.view(-1)\n",
    "            \n",
    "            loss = criterion(outputs_flat, diacritics_flat)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            predictions = outputs_flat.argmax(dim=1)\n",
    "            mask = diacritics_flat != 0\n",
    "            correct += (predictions[mask] == diacritics_flat[mask]).sum().item()\n",
    "            total += mask.sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), correct / total if total > 0 else 0\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\\n\")\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\\n\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f\"Model saved to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:10:33.762798Z",
     "iopub.status.busy": "2026-02-13T19:10:33.762420Z",
     "iopub.status.idle": "2026-02-13T19:10:34.087808Z",
     "shell.execute_reply": "2026-02-13T19:10:34.087062Z",
     "shell.execute_reply.started": "2026-02-13T19:10:33.762769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to diacritization_model.onnx\n",
      "ONNX model verified successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/onnx/symbolic_opset9.py:4662: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare dummy input for ONNX export\n",
    "dummy_input = torch.randint(0, len(char_to_idx), (1, MAX_SEQ_LENGTH)).to(device)\n",
    "\n",
    "# Export\n",
    "model.eval()\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    ONNX_PATH,\n",
    "    export_params=True,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size', 1: 'sequence'},\n",
    "        'output': {0: 'batch_size', 1: 'sequence'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model exported to {ONNX_PATH}\")\n",
    "\n",
    "# Verify ONNX model\n",
    "onnx_model = onnx.load(ONNX_PATH)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model verified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:10:34.088961Z",
     "iopub.status.busy": "2026-02-13T19:10:34.088717Z",
     "iopub.status.idle": "2026-02-13T19:10:34.788374Z",
     "shell.execute_reply": "2026-02-13T19:10:34.787396Z",
     "shell.execute_reply.started": "2026-02-13T19:10:34.088938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking PyTorch model...\n",
      "PyTorch - Mean: 0.49ms, Std: 0.04ms\n",
      "\n",
      "Benchmarking ONNX model...\n",
      "ONNX - Mean: 5.33ms, Std: 5.37ms\n",
      "\n",
      "Speedup: 0.09x\n",
      "\n",
      "Throughput:\n",
      "PyTorch: 2054.99 sequences/second\n",
      "ONNX: 187.46 sequences/second\n"
     ]
    }
   ],
   "source": [
    "def benchmark_pytorch(model, device, num_iterations=100):\n",
    "    \"\"\"Benchmark PyTorch model\"\"\"\n",
    "    model.eval()\n",
    "    test_input = torch.randint(0, len(char_to_idx), (1, MAX_SEQ_LENGTH)).to(device)\n",
    "    \n",
    "    # Warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(test_input)\n",
    "    \n",
    "    # Benchmark\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_iterations):\n",
    "            start = time.time()\n",
    "            _ = model(test_input)\n",
    "            times.append(time.time() - start)\n",
    "    \n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "def benchmark_onnx(onnx_path, num_iterations=100):\n",
    "    \"\"\"Benchmark ONNX model\"\"\"\n",
    "    session = ort.InferenceSession(onnx_path)\n",
    "    test_input = np.random.randint(0, len(char_to_idx), (1, MAX_SEQ_LENGTH), dtype=np.int64)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(10):\n",
    "        _ = session.run(None, {'input': test_input})\n",
    "    \n",
    "    # Benchmark\n",
    "    times = []\n",
    "    for _ in range(num_iterations):\n",
    "        start = time.time()\n",
    "        _ = session.run(None, {'input': test_input})\n",
    "        times.append(time.time() - start)\n",
    "    \n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "# Run benchmarks\n",
    "print(\"Benchmarking PyTorch model...\")\n",
    "pytorch_mean, pytorch_std = benchmark_pytorch(model, device)\n",
    "print(f\"PyTorch - Mean: {pytorch_mean*1000:.2f}ms, Std: {pytorch_std*1000:.2f}ms\")\n",
    "\n",
    "print(\"\\nBenchmarking ONNX model...\")\n",
    "onnx_mean, onnx_std = benchmark_onnx(ONNX_PATH)\n",
    "print(f\"ONNX - Mean: {onnx_mean*1000:.2f}ms, Std: {onnx_std*1000:.2f}ms\")\n",
    "\n",
    "print(f\"\\nSpeedup: {pytorch_mean/onnx_mean:.2f}x\")\n",
    "\n",
    "# Throughput calculation\n",
    "pytorch_throughput = 1.0 / pytorch_mean\n",
    "onnx_throughput = 1.0 / onnx_mean\n",
    "\n",
    "print(f\"\\nThroughput:\")\n",
    "print(f\"PyTorch: {pytorch_throughput:.2f} sequences/second\")\n",
    "print(f\"ONNX: {onnx_throughput:.2f} sequences/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:10:34.789737Z",
     "iopub.status.busy": "2026-02-13T19:10:34.789481Z",
     "iopub.status.idle": "2026-02-13T19:10:34.803903Z",
     "shell.execute_reply": "2026-02-13T19:10:34.803037Z",
     "shell.execute_reply.started": "2026-02-13T19:10:34.789715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing predictions on test samples:\n",
      "\n",
      "Sample 1:\n",
      "Undiacritized: وإذا اختلفا في حائط بين دارين ،\n",
      "Original:      وَإِذَا اخْتَلَفَا فِي حَائِطٍ بَيْنَ دَارَيْنِ ،\n",
      "Predicted:     وَإِذَاَ َاُخْتَلَفَاَ َفِيَ ِحَاْئِطٍ ِبَيْنَ ِدَاَرَيْنِ َ،َ\n",
      "\n",
      "Sample 2:\n",
      "Undiacritized: فلم يكن في العرب ملوك يدفع بعضهم عن بعض ،\n",
      "Original:      فَلَمْ يَكُنْ فِي العَرَبِ مُلُوكٌ يَدْفَعُ بَعْضُهُمْ عَنْ بَعْضٍ ،\n",
      "Predicted:     فَلَمْ ِيَكُنْ ِفِيَ ِاَلْعَرَبِ ِمُلُوِّكٌ َيَدْفَعُ ِبَعْضُهُمْ ِعَنْ ِبَعْضٍ \n",
      "\n",
      "Sample 3:\n",
      "Undiacritized: بين الخطبتين .\n",
      "Original:      بَيْنَ الخُطْبَتَيْنِ .\n",
      "Predicted:     بَيْنَ ِاَلْخُطْبَتَيْنِ ِ.َ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_diacritics(text, model, char_to_idx, idx_to_diac, device, max_length=MAX_SEQ_LENGTH):\n",
    "    \"\"\"Predict diacritics for undiacritized text\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Remove any existing diacritics\n",
    "    text = remove_diacritics(text)\n",
    "    \n",
    "    # Encode\n",
    "    char_indices = [char_to_idx.get(c, char_to_idx['<UNK>']) for c in text[:max_length]]\n",
    "    char_indices += [0] * (max_length - len(char_indices))\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor([char_indices], dtype=torch.long).to(device)\n",
    "        output = model(input_tensor)\n",
    "        predictions = output.argmax(dim=-1).squeeze().cpu().numpy()\n",
    "    \n",
    "    # Reconstruct\n",
    "    result = []\n",
    "    for i, char in enumerate(text):\n",
    "        result.append(char)\n",
    "        diac = idx_to_diac.get(predictions[i], '')\n",
    "        if diac:\n",
    "            result.append(diac)\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "# Test on test samples\n",
    "print(\"Testing predictions on test samples:\\n\")\n",
    "for i in range(min(3, len(test_paired_data))):\n",
    "    sample = test_paired_data[i]\n",
    "    original = sample['diacritized']\n",
    "    undiacritized = sample['undiacritized']\n",
    "    predicted = predict_diacritics(undiacritized, model, char_to_idx, idx_to_diac, device)\n",
    "    \n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Undiacritized: {undiacritized[:80]}\")\n",
    "    print(f\"Original:      {original[:80]}\")\n",
    "    print(f\"Predicted:     {predicted[:80]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:10:34.806943Z",
     "iopub.status.busy": "2026-02-13T19:10:34.806630Z",
     "iopub.status.idle": "2026-02-13T19:11:01.784916Z",
     "shell.execute_reply": "2026-02-13T19:11:01.783872Z",
     "shell.execute_reply.started": "2026-02-13T19:10:34.806919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "Test Results:\n",
      "  Test Loss: 0.1326\n",
      "  Test Accuracy: 0.9567\n",
      "  Test Error Rate: 4.33%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\\n\")\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Test Results:\")\n",
    "print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  Test Error Rate: {(1-test_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:11:01.794555Z",
     "iopub.status.busy": "2026-02-13T19:11:01.794239Z",
     "iopub.status.idle": "2026-02-13T19:11:01.802445Z",
     "shell.execute_reply": "2026-02-13T19:11:01.801694Z",
     "shell.execute_reply.started": "2026-02-13T19:11:01.794521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL SUMMARY\n",
      "============================================================\n",
      "\n",
      "Dataset:\n",
      "  Training sentences: 150000 (150000 pairs)\n",
      "  Validation sentences: 150000 (150000 pairs)\n",
      "  Test sentences: 150000 (150000 pairs)\n",
      "  Total: 450000 sentences\n",
      "\n",
      "Model Architecture:\n",
      "  Embedding dim: 64\n",
      "  Hidden dim: 128\n",
      "  Num layers: 2\n",
      "  Total parameters: 613,980\n",
      "\n",
      "Vocabulary:\n",
      "  Character vocab size: 201\n",
      "  Diacritic classes: 28\n",
      "\n",
      "Performance:\n",
      "  Final validation accuracy: 0.9567\n",
      "  Test accuracy: 0.9567\n",
      "\n",
      "Files:\n",
      "  PyTorch model: diacritization_model.pth (2401.87 KB)\n",
      "  ONNX model: diacritization_model.onnx (2402.70 KB)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Training sentences: {len(train_sentences)} ({len(train_paired_data)} pairs)\")\n",
    "print(f\"  Validation sentences: {len(val_sentences)} ({len(val_paired_data)} pairs)\")\n",
    "print(f\"  Test sentences: {len(test_sentences)} ({len(test_paired_data)} pairs)\")\n",
    "print(f\"  Total: {len(train_sentences) + len(val_sentences) + len(test_sentences)} sentences\")\n",
    "\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"  Embedding dim: {EMBEDDING_DIM}\")\n",
    "print(f\"  Hidden dim: {HIDDEN_DIM}\")\n",
    "print(f\"  Num layers: {NUM_LAYERS}\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "print(f\"\\nVocabulary:\")\n",
    "print(f\"  Character vocab size: {len(char_to_idx)}\")\n",
    "print(f\"  Diacritic classes: {len(diac_to_idx)}\")\n",
    "\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Final validation accuracy: {val_acc:.4f}\")\n",
    "print(f\"  Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nFiles:\")\n",
    "print(f\"  PyTorch model: {MODEL_PATH} ({os.path.getsize(MODEL_PATH)/1024:.2f} KB)\")\n",
    "print(f\"  ONNX model: {ONNX_PATH} ({os.path.getsize(ONNX_PATH)/1024:.2f} KB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
