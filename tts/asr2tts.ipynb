{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ™ï¸ Hybrid Low-Resource TTS Dataset Synthesis Pipeline\n",
    "\n",
    "Blog post: https://blog.openvoiceos.org/posts/2025-12-09-ast\n",
    "\n",
    "ASR Datasets of interest: https://datacollective.mozillafoundation.org/datasets?q=scripted+speech\n",
    "\n",
    "This notebook implements the whitepaper workflow: **Format Conversion -> Denoising -> Trimming -> Normalization -> WPM Filtering -> Voice Cloning**.\n",
    "\n",
    "### Usage Instructions:\n",
    "1. **Configure Variables:** Set your base paths in the first code cell.\n",
    "2. **Run Sequentially:** Execute cells in order. Dependencies are re-installed per step to avoid conflicts.\n",
    "3. **Check Outputs:** Each step will output to a subdirectory within your `WORK_DIR`.\n",
    "\n",
    "Example datasets generated with this method:\n",
    "- https://huggingface.co/datasets/TigreGotico/tts_vc_mcv-scripted-v23.0_ast_miro\n",
    "- https://huggingface.co/datasets/TigreGotico/tts_vc_mcv-scripted-v23.0_ast_dii\n",
    "- https://huggingface.co/datasets/TigreGotico/tts_vc_mcv-scripted-v23.0_an_miro\n",
    "- https://huggingface.co/datasets/TigreGotico/tts_vc_mcv-scripted-v23.0_an_dii\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# âš™ï¸ GLOBAL CONFIGURATION (ENV VARS)\n",
    "# ==========================================\n",
    "\n",
    "# Base directory for processing\n",
    "os.environ[\"WORK_DIR\"] = \"/run/media/miro/endeavouros/processing_workspace\"\n",
    "\n",
    "# Input Data Sources\n",
    "os.environ[\"RAW_AUDIO_SOURCE\"] = \"/run/media/miro/endeavouros/TTS_datasets/raw_audio\"\n",
    "os.environ[\"METADATA_CSV\"] = \"/run/media/miro/endeavouros/TTS_datasets/metadata.csv\"\n",
    "os.environ[\"REF_VOICES_DIR\"] = \"/run/media/miro/endeavouros/ref_voices\"\n",
    "\n",
    "# Processing Parameters\n",
    "os.environ[\"TARGET_LUFS\"] = \"-20.0\"\n",
    "os.environ[\"WPM_STD_THRESHOLD\"] = \"2.0\"\n",
    "os.environ[\"MIN_TRIM_DURATION\"] = \"1.0\"\n",
    "os.environ[\"DEVICE\"] = \"cuda\" # or cpu, mps\n",
    "\n",
    "# Define pipeline subdirectories (Chain of custody)\n",
    "base = os.environ[\"WORK_DIR\"]\n",
    "os.environ[\"DIR_CONVERTED\"] = os.path.join(base, \"1_converted\")\n",
    "os.environ[\"DIR_DENOISED\"] = os.path.join(base, \"2_denoised\")\n",
    "os.environ[\"DIR_TRIMMED\"] = os.path.join(base, \"3_trimmed\")\n",
    "os.environ[\"DIR_NORMALIZED\"] = os.path.join(base, \"4_normalized\")\n",
    "os.environ[\"DIR_FILTERED\"] = os.path.join(base, \"5_wpm_filtered\")\n",
    "os.environ[\"DIR_FINAL_VC\"] = os.path.join(base, \"6_vc_output\")\n",
    "\n",
    "print(f\"Work Directory: {os.environ['WORK_DIR']}\")\n",
    "print(f\"Target Device: {os.environ['DEVICE']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Step 1: Format Standardization\n",
    "Converts mixed audio formats (mp3, ogg, flv, etc.) to standard WAV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstall specific dependencies for this step\n",
    "!pip install pydub -q\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pydub import AudioSegment\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_DIR = os.environ.get(\"RAW_AUDIO_SOURCE\")\n",
    "OUTPUT_DIR = os.environ.get(\"DIR_CONVERTED\")\n",
    "\n",
    "SUPPORTED_FORMATS = {'.mp3', '.mp4', '.wma', '.ogg', '.flv', '.aac', '.m4a', '.amr', '.wav'}\n",
    "\n",
    "def convert_dataset(input_path, output_path):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    print(f\"Converting from {input_path} -> {output_path}\")\n",
    "    \n",
    "    for root, _, files in os.walk(input_path):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            \n",
    "            if ext.lower() not in SUPPORTED_FORMATS:\n",
    "                continue\n",
    "\n",
    "            target_file = os.path.join(output_path, f\"{base}.wav\")\n",
    "            \n",
    "            # If already wav, just copy to standardize location, else convert\n",
    "            if ext.lower() == '.wav':\n",
    "                shutil.copy2(file_path, target_file)\n",
    "            else:\n",
    "                try:\n",
    "                    audio = AudioSegment.from_file(file_path)\n",
    "                    audio.export(target_file, format='wav')\n",
    "                    print(f\"Converted: {filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to convert {filename}: {e}\")\n",
    "\n",
    "convert_dataset(INPUT_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Audio Denoising\n",
    "Uses `resemble-enhance` to remove background noise and enhance speech quality.\n",
    "*Note: This step can be resource intensive.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstall specific dependencies for this step\n",
    "!pip install resemble-enhance torchaudio --upgrade -q\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from resemble_enhance.enhancer.inference import denoise\n",
    "\n",
    "INPUT_DIR = os.environ.get(\"DIR_CONVERTED\")\n",
    "OUTPUT_DIR = os.environ.get(\"DIR_DENOISED\")\n",
    "DEVICE = os.environ.get(\"DEVICE\", \"cpu\")\n",
    "\n",
    "def process_denoising(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith(\".wav\")]\n",
    "    \n",
    "    for fname in tqdm(files, desc=\"Denoising Audio\"):\n",
    "        in_path = os.path.join(input_dir, fname)\n",
    "        out_path = os.path.join(output_dir, fname)\n",
    "        \n",
    "        if os.path.exists(out_path):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            dwav, sr = torchaudio.load(in_path)\n",
    "            # Mono mix if necessary\n",
    "            if dwav.shape[0] > 1:\n",
    "                dwav = dwav.mean(dim=0)\n",
    "            else:\n",
    "                dwav = dwav.squeeze(0)\n",
    "            \n",
    "            # Denoise\n",
    "            denoised_wav, new_sr = denoise(dwav, sr, DEVICE)\n",
    "            \n",
    "            # Save\n",
    "            torchaudio.save(out_path, denoised_wav.unsqueeze(0), new_sr)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "process_denoising(INPUT_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Silence Trimming\n",
    "Trims leading/trailing silence using `librosa`. Removes files that are too short after trimming.\n",
    "\n",
    "FUTURE WORK: a VAD engine could be used here instead such as https://github.com/OpenVoiceOS/ovos-vad-plugin-silero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstall specific dependencies for this step\n",
    "!pip install librosa soundfile -q\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "INPUT_DIR = os.environ.get(\"DIR_DENOISED\")\n",
    "OUTPUT_DIR = os.environ.get(\"DIR_TRIMMED\")\n",
    "MIN_DURATION = float(os.environ.get(\"MIN_TRIM_DURATION\", 1.0))\n",
    "\n",
    "def trim_silence(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    files = glob(os.path.join(input_dir, '*.wav'))\n",
    "    \n",
    "    for fpath in tqdm(files, desc=\"Trimming Silence\"):\n",
    "        fname = os.path.basename(fpath)\n",
    "        out_path = os.path.join(output_dir, fname)\n",
    "        \n",
    "        try:\n",
    "            # Load\n",
    "            audio, sr = librosa.load(fpath, sr=None, mono=True)\n",
    "            \n",
    "            # Trim\n",
    "            trimmed_audio, _ = librosa.effects.trim(audio, top_db=40)\n",
    "            duration = len(trimmed_audio) / sr\n",
    "            \n",
    "            # Filter short files\n",
    "            if duration >= MIN_DURATION:\n",
    "                sf.write(out_path, trimmed_audio, sr)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "trim_silence(INPUT_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Volume Normalization\n",
    "Normalizes audio to a target loudness (e.g., -20.0 LUFS/dBFS) to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstall specific dependencies for this step\n",
    "!pip install pydub -q\n",
    "\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "INPUT_DIR = os.environ.get(\"DIR_TRIMMED\")\n",
    "OUTPUT_DIR = os.environ.get(\"DIR_NORMALIZED\")\n",
    "TARGET_DBFS = float(os.environ.get(\"TARGET_LUFS\", -20.0))\n",
    "\n",
    "def normalize_volume(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    files = glob(os.path.join(input_dir, '*.wav'))\n",
    "    \n",
    "    for fpath in tqdm(files, desc=\"Normalizing Volume\"):\n",
    "        fname = os.path.basename(fpath)\n",
    "        out_path = os.path.join(output_dir, fname)\n",
    "        \n",
    "        try:\n",
    "            audio = AudioSegment.from_wav(fpath)\n",
    "            current_dbfs = audio.dBFS\n",
    "            gain = TARGET_DBFS - current_dbfs\n",
    "            \n",
    "            normalized = audio.apply_gain(gain)\n",
    "            normalized.export(out_path, format=\"wav\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error normalizing {fname}: {e}\")\n",
    "\n",
    "normalize_volume(INPUT_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: WPM (Words Per Minute) Filtering\n",
    "Filters out outliers based on speaking rate using the provided transcript CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstall specific dependencies for this step\n",
    "!pip install pandas soundfile -q\n",
    "\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "\n",
    "INPUT_DIR = os.environ.get(\"DIR_NORMALIZED\")\n",
    "CSV_PATH = os.environ.get(\"METADATA_CSV\")\n",
    "OUTPUT_DIR = os.environ.get(\"DIR_FILTERED\")\n",
    "STD_THRESHOLD = float(os.environ.get(\"WPM_STD_THRESHOLD\", 2.0))\n",
    "\n",
    "def calculate_wpm(row, audio_dir):\n",
    "    file_path = os.path.join(audio_dir, str(row['file_name']))\n",
    "    # Handle missing extensions in CSV if necessary\n",
    "    if not file_path.endswith('.wav') and not os.path.exists(file_path):\n",
    "         file_path += \".wav\"\n",
    "         \n",
    "    cleaned_transcript = re.sub(r'[^\\w\\s]', '', str(row['transcript'])).strip().lower()\n",
    "    word_count = len(cleaned_transcript.split())\n",
    "\n",
    "    if word_count == 0 or not os.path.exists(file_path):\n",
    "        return 0.0\n",
    "\n",
    "    try:\n",
    "        with sf.SoundFile(file_path) as f:\n",
    "            duration_min = (len(f) / f.samplerate) / 60.0\n",
    "        return word_count / duration_min if duration_min > 0 else 0.0\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def filter_wpm(input_dir, csv_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load CSV (Assuming Pipe separated)\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, sep='|', names=['file_name', 'transcript'], header=None)\n",
    "    except:\n",
    "        # Fallback for standard CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "    print(\"Calculating WPM...\")\n",
    "    df['WPM'] = df.apply(lambda row: calculate_wpm(row, input_dir), axis=1)\n",
    "    valid_data = df[df['WPM'] > 0]\n",
    "    \n",
    "    # Stats\n",
    "    mean_wpm = valid_data['WPM'].mean()\n",
    "    std_wpm = valid_data['WPM'].std()\n",
    "    lower = mean_wpm - (STD_THRESHOLD * std_wpm)\n",
    "    upper = mean_wpm + (STD_THRESHOLD * std_wpm)\n",
    "    \n",
    "    print(f\"Mean WPM: {mean_wpm:.2f} | Range: {lower:.2f} - {upper:.2f}\")\n",
    "    \n",
    "    filtered = valid_data[(valid_data['WPM'] >= lower) & (valid_data['WPM'] <= upper)]\n",
    "    \n",
    "    print(f\"Copying {len(filtered)} valid files...\")\n",
    "    new_meta = []\n",
    "    for _, row in filtered.iterrows():\n",
    "        fname = str(row['file_name'])\n",
    "        if not fname.endswith('.wav'): fname += \".wav\"\n",
    "        \n",
    "        src = os.path.join(input_dir, fname)\n",
    "        dst = os.path.join(output_dir, fname)\n",
    "        \n",
    "        if os.path.exists(src):\n",
    "            shutil.copy2(src, dst)\n",
    "            new_meta.append(f\"{fname}|{row['transcript']}\")\n",
    "            \n",
    "    # Save new metadata\n",
    "    with open(os.path.join(output_dir, \"metadata_filtered.csv\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(new_meta))\n",
    "\n",
    "filter_wpm(INPUT_DIR, CSV_PATH, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Voice Conversion (Synthesis)\n",
    "\n",
    "Generates the final synthetic dataset using `ChatterboxVC` and the reference voices.\n",
    "\n",
    "A different VC engine can be integrated here, ChatterboxVC is what we originally used but more recent options exist with better performance and would cut down notebook runtime considerably.\n",
    "\n",
    "https://github.com/TigreGotico/chatterbox-onnx is also available if using torch is not possible or you want to run this step on CPU\n",
    "\n",
    "FUTURE WORK: make VC engine configurable via env vars and support various options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstall specific dependencies for this step\n",
    "!pip install torch torchaudio tqdm chatterbox -q\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchaudio as ta\n",
    "from chatterbox.vc import ChatterboxVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "INPUT_DIR = os.environ.get(\"DIR_FILTERED\")\n",
    "OUTPUT_BASE = os.environ.get(\"DIR_FINAL_VC\")\n",
    "REFS_FOLDER = os.environ.get(\"REF_VOICES_DIR\")\n",
    "DEVICE = os.environ.get(\"DEVICE\", \"cpu\")\n",
    "\n",
    "def run_voice_conversion():\n",
    "    print(f\"Loading Model on {DEVICE}...\")\n",
    "    try:\n",
    "        model = ChatterboxVC.from_pretrained(DEVICE)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model: {e}\")\n",
    "        return\n",
    "\n",
    "    ref_voices = [f for f in os.listdir(REFS_FOLDER) if f.endswith('.wav')]\n",
    "    source_files = [f for f in os.listdir(INPUT_DIR) if f.endswith('.wav')]\n",
    "\n",
    "    for ref_voice in tqdm(ref_voices, desc=\"Processing Ref Voices\"):\n",
    "        voice_id = os.path.splitext(ref_voice)[0]\n",
    "        ref_path = os.path.join(REFS_FOLDER, ref_voice)\n",
    "        \n",
    "        voice_out_dir = os.path.join(OUTPUT_BASE, voice_id)\n",
    "        os.makedirs(voice_out_dir, exist_ok=True)\n",
    "\n",
    "        for fname in tqdm(source_files, desc=f\"Converting to {voice_id}\", leave=False):\n",
    "            out_file = os.path.join(voice_out_dir, fname)\n",
    "            if os.path.exists(out_file):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                wav = model.generate(\n",
    "                    audio=os.path.join(INPUT_DIR, fname),\n",
    "                    target_voice_path=ref_path,\n",
    "                )\n",
    "                ta.save(out_file, wav, model.sr)\n",
    "            except Exception as e:\n",
    "                # Silent fail to keep loop moving\n",
    "                continue\n",
    "\n",
    "run_voice_conversion()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "_________________\n",
    "\n",
    "# Step 7\n",
    "\n",
    "Prepare metadata.csv, restore punctuation if dataset needs it\n",
    "\n",
    "When transcripts are long/missing punctuation this preprocessing step will help for later splitting into smaller sentences/paragraphs\n",
    "\n",
    "https://github.com/oliverguhr/deepmultilingualpunctuation"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T16:24:10.845742Z",
     "start_time": "2026-02-14T16:23:53.876426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install deepmultilingualpunctuation tf-keras\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "\n",
    "\n",
    "CSV_PATH = os.environ.get(\"METADATA_CSV\") or \"metadata.csv\"\n",
    "OUTPUT_PATH = os.environ.get(\"OUTPUT_CSV\") or \"metadata_punct.csv\"\n",
    "\n",
    "# Load CSV (Assuming Pipe separated)\n",
    "try:\n",
    "    df = pd.read_csv(CSV_PATH, sep='|', names=['file_name', 'transcript'], header=None)\n",
    "except:\n",
    "    # Fallback for standard CSV\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "\n",
    "model = PunctuationModel(\"kredor/punctuate-all\")\n",
    "\n",
    "def restore_punct(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return text\n",
    "    try:\n",
    "        return model.restore_punctuation(text)\n",
    "    except Exception:\n",
    "        return text\n",
    "\n",
    "# Apply to DataFrame\n",
    "print(\"Restoring punctuation... this may take a while depending on dataset size.\")\n",
    "df['transcript'] = df['transcript'].apply(restore_punct)\n",
    "\n",
    "# Save the updated metadata\n",
    "df.to_csv(OUTPUT_PATH, sep='|', index=False, header=False)\n",
    "print(f\"Done! Saved to {OUTPUT_PATH}\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepmultilingualpunctuation in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: tf-keras in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (2.20.1)\r\n",
      "Requirement already satisfied: torch>=1.8.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from deepmultilingualpunctuation) (2.9.1)\r\n",
      "Requirement already satisfied: transformers in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from deepmultilingualpunctuation) (4.53.3)\r\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tf-keras) (2.20.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.12.19)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\r\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\r\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (24.2)\r\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (5.29.5)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.5)\r\n",
      "Requirement already satisfied: setuptools in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.10.2)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.3.0)\r\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.15.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.1.1)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.76.0)\r\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\r\n",
      "Requirement already satisfied: keras>=3.10.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.12.0)\r\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.26.4)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.15.1)\r\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.4)\r\n",
      "Requirement already satisfied: filelock in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.20.3)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (1.14.0)\r\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.6.1)\r\n",
      "Requirement already satisfied: jinja2 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (2024.12.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.8.93)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.8.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (11.3.3.83)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (10.3.9.90)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (11.7.3.90)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.5.8.93)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (2.27.5)\r\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.3.20)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.8.93)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (1.13.1.3)\r\n",
      "Requirement already satisfied: triton==3.5.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.5.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from transformers->deepmultilingualpunctuation) (0.36.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from transformers->deepmultilingualpunctuation) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from transformers->deepmultilingualpunctuation) (2026.1.15)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from transformers->deepmultilingualpunctuation) (0.21.4)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from transformers->deepmultilingualpunctuation) (0.7.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from transformers->deepmultilingualpunctuation) (4.67.3)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers->deepmultilingualpunctuation) (1.2.0)\r\n",
      "Requirement already satisfied: rich in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.3.2)\r\n",
      "Requirement already satisfied: namex in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\r\n",
      "Requirement already satisfied: optree in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (1.26.20)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2026.1.4)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.8.1->deepmultilingualpunctuation) (1.3.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.10.1)\r\n",
      "Requirement already satisfied: pillow in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (12.1.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from jinja2->torch>=1.8.1->deepmultilingualpunctuation) (3.0.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (4.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m26.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/miro/PycharmProjects/wakeHuBert/.venv/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:181: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.NONE\"` instead.\n",
      "  warnings.warn(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring punctuation... this may take a while depending on dataset size.\n",
      "Done! Saved to /run/media/miro/endeavouros/VC_datasets/ast_fleurs/metadata_punct.csv\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
