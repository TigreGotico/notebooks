{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phoonnx — Train & Export TTS Models\n",
    "\n",
    "**A platform-agnostic notebook for training [VITS](https://arxiv.org/abs/2106.06103)-based Text-to-Speech models with [phoonnx](https://github.com/TigreGotico/phoonnx).**\n",
    "\n",
    "This notebook is **self-contained** — it does not depend on external scripts and works on **Kaggle, Colab, Paperspace, SageMaker, local machines**, or any Jupyter-compatible environment.\n",
    "\n",
    "### What phoonnx does\n",
    "\n",
    "phoonnx is a multilingual TTS toolkit built on the VITS architecture. It provides:\n",
    "- Text normalization (numbers, dates, units, contractions — language-aware)\n",
    "- Phonemization via 25+ backends (eSpeak, Gruut, ByT5, Misaki, Epitran, …)\n",
    "- Training with PyTorch Lightning\n",
    "- Export to ONNX for lightweight, cross-platform inference\n",
    "\n",
    "Trained models work with **Piper TTS**, **sherpa-onnx**, **Open Voice OS**, and the **[NVDA screen-reader add-on](https://github.com/TigreGotico/phoonnx-AddonNVDA)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 · Configuration\n",
    "\n",
    "Edit the variables below to match your language, dataset, and hardware.\n",
    "All paths are auto-resolved per platform — you **only** need to change the top section."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:34:00.150949Z",
     "start_time": "2026-02-14T23:34:00.146059Z"
    }
   },
   "source": [
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# ║  EDIT THIS SECTION — everything else adapts automatically          ║\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "# ── Language & phonemizer ────────────────────────────────────────────\n",
    "LANG            = \"en\"            # BCP-47 language tag (e.g. \"en\", \"pt-PT\", \"eu-ES\")\n",
    "PHONEMIZER      = \"espeak\"        # one of: espeak, gruut, byt5, misaki, epitran, …\n",
    "                                  #   see full list in TRAINING.md\n",
    "ALPHABET        = \"ipa\"           # ipa, arpa, sampa, pinyin, hangul, kana, …\n",
    "\n",
    "# ── Dataset source (pick ONE) ───────────────────────────────────────\n",
    "#    Option A – download from Hugging Face\n",
    "HF_DATASET      = \"TigreGotico/tts-train-synthetic-miro_en-US\"\n",
    "#    Option B – upload the dataset yourself and set the path\n",
    "#HF_DATASET = \"\"   # leave empty to skip download\n",
    "\n",
    "#    Browse available datasets:\n",
    "#    https://huggingface.co/collections/TigreGotico/synthetic-tts-datasets\n",
    "\n",
    "# ── Base checkpoint for fine-tuning (optional) ──────────────────────\n",
    "#    Set both to \"\" to train from scratch.\n",
    "BASE_CKPT_URL   = \"https://huggingface.co/OpenVoiceOS/phoonnx_eu-ES_miro_espeak/resolve/main/epoch%3D299-step%3D99600.ckpt\"\n",
    "BASE_CONFIG_URL = \"https://huggingface.co/OpenVoiceOS/phoonnx_eu-ES_miro_espeak/resolve/main/miro_eu-ES.json\"\n",
    "\n",
    "# ── Hugging Face token (for private datasets / avoid rate limits) ───\n",
    "HF_TOKEN        = \"\"              # e.g. \"hf_xxxxx\"\n",
    "\n",
    "# ── Training hyperparameters ────────────────────────────────────────\n",
    "BATCH_SIZE      = 16              # reduce to 8 or 4 if you run out of VRAM\n",
    "MAX_EPOCHS      = 1000            # training will checkpoint every epoch\n",
    "PRECISION       = 32              # 32, 16, or \"bf16\"  (16 saves ~40 % VRAM)\n",
    "LEARNING_RATE   = 2e-4\n",
    "VALIDATION_SPLIT= 0.05\n",
    "QUALITY         = \"medium\"        # x-low, medium, high  (affects model size)\n",
    "SAMPLE_RATE     = 22050           # must match your audio files\n",
    "\n",
    "# ── Extra flags ─────────────────────────────────────────────────────\n",
    "SINGLE_SPEAKER  = True            # set False for multi-speaker datasets\n",
    "ADD_DIACRITICS  = False           # True for Arabic (tashkeel) / Hebrew (nikud)\n",
    "BYT5_MODEL      = \"\"              # only if PHONEMIZER=\"byt5\", e.g.\n",
    "                                  #   \"OpenVoiceOS/g2p-mbyt5-12l-ipa-childes-espeak-onnx\"\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# ║  END OF USER CONFIG — everything below is auto-configured          ║\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 · Platform detection & paths\n",
    "\n",
    "The cell below detects whether you are on **Kaggle, Colab, Paperspace, SageMaker**, or a **local** machine and sets all working paths accordingly. No manual edits needed."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:35:02.725650Z",
     "start_time": "2026-02-14T23:35:02.658661Z"
    }
   },
   "source": [
    "import os, shutil, subprocess, sys\n",
    "\n",
    "# ── Detect platform ─────────────────────────────────────────────────\n",
    "def detect_platform():\n",
    "    if os.path.exists(\"/kaggle\"):\n",
    "        return \"kaggle\"\n",
    "    try:\n",
    "        import google.colab  # noqa: F401\n",
    "        return \"colab\"\n",
    "    except ImportError:\n",
    "        pass\n",
    "    if os.environ.get(\"PAPERSPACE\"):\n",
    "        return \"paperspace\"\n",
    "    if os.path.exists(\"/opt/ml\"):\n",
    "        return \"sagemaker\"\n",
    "    return \"local\"\n",
    "\n",
    "PLATFORM = detect_platform()\n",
    "print(f\"Detected platform: {PLATFORM}\")\n",
    "\n",
    "# ── Detect accelerator ──────────────────────────────────────────────\n",
    "def detect_accelerator():\n",
    "    try:\n",
    "        subprocess.check_output([\"nvidia-smi\"], stderr=subprocess.DEVNULL)\n",
    "        return \"gpu\"\n",
    "    except (FileNotFoundError, subprocess.CalledProcessError):\n",
    "        pass\n",
    "    # Apple Silicon (MPS) — PyTorch >= 2.0\n",
    "    try:\n",
    "        import torch\n",
    "        if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "            return \"mps\"\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return \"cpu\"\n",
    "\n",
    "ACCELERATOR = detect_accelerator()\n",
    "print(f\"Accelerator: {ACCELERATOR}\")\n",
    "if ACCELERATOR == \"cpu\":\n",
    "    print(\"⚠  CPU training is very slow — GPU is strongly recommended.\")\n",
    "\n",
    "# ── Resolve paths per platform ──────────────────────────────────────\n",
    "WORK = {\n",
    "    \"kaggle\":     \"/kaggle/working\",\n",
    "    \"colab\":      \"/content\",\n",
    "    \"paperspace\": \"/notebooks\",\n",
    "    \"sagemaker\":  \"/opt/ml\",\n",
    "    \"local\":      os.path.expanduser(\"~/phoonnx_work\"),\n",
    "}[PLATFORM]\n",
    "\n",
    "os.makedirs(WORK, exist_ok=True)\n",
    "\n",
    "DATASET_DIR       = os.path.join(WORK, \"dataset\")\n",
    "PREPROCESSED_DIR  = os.path.join(WORK, \"training\")\n",
    "CHECKPOINTS_DIR   = os.path.join(WORK, \"checkpoints\")\n",
    "EXPORT_DIR        = os.path.join(WORK, \"exported\")\n",
    "\n",
    "for d in [DATASET_DIR, PREPROCESSED_DIR, CHECKPOINTS_DIR, EXPORT_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "LOCAL_CKPT   = os.path.join(CHECKPOINTS_DIR, \"base.ckpt\")\n",
    "LOCAL_CONFIG = os.path.join(CHECKPOINTS_DIR, \"base.ckpt.json\")\n",
    "\n",
    "print(f\"Working directory : {WORK}\")\n",
    "print(f\"Dataset path      : {DATASET_DIR}\")\n",
    "print(f\"Preprocessed path : {PREPROCESSED_DIR}\")\n",
    "print(f\"Checkpoints path  : {CHECKPOINTS_DIR}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected platform: local\n",
      "Accelerator: gpu\n",
      "Working directory : /home/miro/phoonnx_work\n",
      "Dataset path      : /home/miro/phoonnx_work/dataset\n",
      "Preprocessed path : /home/miro/phoonnx_work/training\n",
      "Checkpoints path  : /home/miro/phoonnx_work/checkpoints\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 · Set environment variables\n",
    "\n",
    "Some phoonnx internals read from environment variables. This cell propagates your config."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:35:05.471702Z",
     "start_time": "2026-02-14T23:35:05.467802Z"
    }
   },
   "source": [
    "# Propagate config to environment (read by phoonnx internals)\n",
    "os.environ[\"LANG\"]          = LANG\n",
    "os.environ[\"PHONEMIZER\"]    = PHONEMIZER\n",
    "os.environ[\"ALPHABET\"]      = ALPHABET\n",
    "os.environ[\"WORKDIR\"]      = WORK\n",
    "if HF_TOKEN:\n",
    "    os.environ[\"HF_TOKEN\"]  = HF_TOKEN\n",
    "if ACCELERATOR == \"gpu\":\n",
    "    os.environ[\"CUDA\"]      = \"1\"   # tells ByT5 phonemizer to use GPU\n",
    "\n",
    "print(\"Environment configured ✓\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured ✓\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 · Install dependencies\n",
    "\n",
    "Installs phoonnx with training extras and builds the Cython monotonic alignment module.\n",
    "This uses a **virtual-env** to ensure a compatible python version\n",
    "and installs directly into the system Python elsewhere.\n",
    "\n",
    "> **Disk usage note**: `phoonnx[train]` pulls in PyTorch + Lightning (~3 GB).\n",
    "> On free-tier Kaggle/Colab this is fine; on very constrained envs, ensure ≥5 GB free."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:35:09.415566Z",
     "start_time": "2026-02-14T23:35:08.745389Z"
    }
   },
   "source": [
    "%%time\n",
    "!uv venv ${WORKDIR}/.venv  --clear --python 3.10\n",
    "\n",
    "VENV_PYTHON = WORK + \"/.venv/bin/python\"\n",
    "os.environ[\"UV_PYTHON\"] = VENV_PYTHON\n",
    "venv_bin = os.path.join(WORK, \".venv\", \"bin\")\n",
    "os.environ[\"PATH\"] = venv_bin + \":\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"VIRTUAL_ENV\"] = os.path.join(WORK, \".venv\")\n",
    "print(f\"Python for training: {VENV_PYTHON}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython \u001B[36m3.10.19\u001B[39m\u001B[36m\u001B[39m\r\n",
      "Creating virtual environment at: \u001B[36m/home/miro/phoonnx_work/.venv\u001B[39m\r\n",
      "Activate with: \u001B[32msource /home/miro/phoonnx_work/.venv/bin/activate\u001B[39m\r\n",
      "Python for training: /home/miro/phoonnx_work/.venv/bin/python\n",
      "CPU times: user 13.3 ms, sys: 3.34 ms, total: 16.7 ms\n",
      "Wall time: 665 ms\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:35:14.157316Z",
     "start_time": "2026-02-14T23:35:12.431475Z"
    }
   },
   "source": [
    "%%time\n",
    "!git clone --depth 1 https://github.com/TigreGotico/phoonnx ${WORKDIR}/phoonnx\n",
    "\n",
    "PHOONNX_DIR = WORK + \"/phoonnx\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/miro/phoonnx_work/phoonnx'...\r\n",
      "remote: Enumerating objects: 223, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (223/223), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (187/187), done.\u001B[K\r\n",
      "remote: Total 223 (delta 17), reused 166 (delta 4), pack-reused 0 (from 0)\u001B[K\r\n",
      "Receiving objects: 100% (223/223), 14.17 MiB | 21.15 MiB/s, done.\r\n",
      "Resolving deltas: 100% (17/17), done.\r\n",
      "CPU times: user 33.7 ms, sys: 12.9 ms, total: 46.5 ms\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:35:18.702403Z",
     "start_time": "2026-02-14T23:35:17.041242Z"
    }
   },
   "source": [
    "%%time\n",
    "!source ${WORKDIR}/.venv/bin/activate && uv pip install -e ${WORKDIR}/phoonnx[train]  \"setuptools<82\"\n",
    "\n",
    "print(\"phoonnx[train] installed ✓\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2mUsing Python 3.10.19 environment at: /home/miro/phoonnx_work/.venv\u001B[0m\r\n",
      "\u001B[2K\u001B[2mResolved \u001B[1m84 packages\u001B[0m \u001B[2min 950ms\u001B[0m\u001B[0m                                        \u001B[0m\r\n",
      "\u001B[2K\u001B[2mPrepared \u001B[1m1 package\u001B[0m \u001B[2min 255ms\u001B[0m\u001B[0m                                              \r\n",
      "\u001B[2K\u001B[2mInstalled \u001B[1m84 packages\u001B[0m \u001B[2min 142ms\u001B[0m\u001B[0m                              \u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1maiohappyeyeballs\u001B[0m\u001B[2m==2.6.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1maiohttp\u001B[0m\u001B[2m==3.13.3\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1maiosignal\u001B[0m\u001B[2m==1.4.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1masync-timeout\u001B[0m\u001B[2m==5.0.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mattrs\u001B[0m\u001B[2m==25.4.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1maudioread\u001B[0m\u001B[2m==3.1.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mcertifi\u001B[0m\u001B[2m==2026.1.4\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mcffi\u001B[0m\u001B[2m==2.0.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mcharset-normalizer\u001B[0m\u001B[2m==3.4.4\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mclick\u001B[0m\u001B[2m==8.3.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mcoloredlogs\u001B[0m\u001B[2m==15.0.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mcombo-lock\u001B[0m\u001B[2m==0.3.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mcython\u001B[0m\u001B[2m==0.29.37\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mdateparser\u001B[0m\u001B[2m==1.3.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mdecorator\u001B[0m\u001B[2m==5.2.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mfilelock\u001B[0m\u001B[2m==3.24.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mflatbuffers\u001B[0m\u001B[2m==25.12.19\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mfrozenlist\u001B[0m\u001B[2m==1.8.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mfsspec\u001B[0m\u001B[2m==2026.2.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mhumanfriendly\u001B[0m\u001B[2m==10.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1midna\u001B[0m\u001B[2m==3.11\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mjoblib\u001B[0m\u001B[2m==1.5.3\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mjson-database\u001B[0m\u001B[2m==0.10.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mkthread\u001B[0m\u001B[2m==0.2.3\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mlangcodes\u001B[0m\u001B[2m==3.5.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mlazy-loader\u001B[0m\u001B[2m==0.4\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mlibrosa\u001B[0m\u001B[2m==0.11.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mlightning-utilities\u001B[0m\u001B[2m==0.15.2\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mllvmlite\u001B[0m\u001B[2m==0.46.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mmarkdown-it-py\u001B[0m\u001B[2m==4.0.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mmdurl\u001B[0m\u001B[2m==0.1.2\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mmemory-tempfile\u001B[0m\u001B[2m==2.2.3\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mmpmath\u001B[0m\u001B[2m==1.3.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mmsgpack\u001B[0m\u001B[2m==1.1.2\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mmultidict\u001B[0m\u001B[2m==6.7.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mnumba\u001B[0m\u001B[2m==0.63.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mnumpy\u001B[0m\u001B[2m==1.26.4\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mnvidia-cublas-cu11\u001B[0m\u001B[2m==11.10.3.66\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mnvidia-cuda-nvrtc-cu11\u001B[0m\u001B[2m==11.7.99\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mnvidia-cuda-runtime-cu11\u001B[0m\u001B[2m==11.7.99\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mnvidia-cudnn-cu11\u001B[0m\u001B[2m==8.5.0.96\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1monnxruntime\u001B[0m\u001B[2m==1.23.2\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1movos-config\u001B[0m\u001B[2m==2.1.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1movos-date-parser\u001B[0m\u001B[2m==0.7.0a5\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1movos-number-parser\u001B[0m\u001B[2m==0.5.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1movos-utils\u001B[0m\u001B[2m==0.8.4\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mpackaging\u001B[0m\u001B[2m==26.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mpexpect\u001B[0m\u001B[2m==4.9.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mphoonnx\u001B[0m\u001B[2m==1.3.2a5 (from file:///home/miro/phoonnx_work/phoonnx)\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mplatformdirs\u001B[0m\u001B[2m==4.9.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mpooch\u001B[0m\u001B[2m==1.9.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mpropcache\u001B[0m\u001B[2m==0.4.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mprotobuf\u001B[0m\u001B[2m==6.33.5\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mptyprocess\u001B[0m\u001B[2m==0.7.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mpycparser\u001B[0m\u001B[2m==3.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mpyee\u001B[0m\u001B[2m==13.0.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mpygments\u001B[0m\u001B[2m==2.19.2\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mpython-dateutil\u001B[0m\u001B[2m==2.9.0.post0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mpytorch-lightning\u001B[0m\u001B[2m==1.9.5\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mpytz\u001B[0m\u001B[2m==2025.2\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mpyyaml\u001B[0m\u001B[2m==6.0.3\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mquebra-frases\u001B[0m\u001B[2m==0.3.7\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mregex\u001B[0m\u001B[2m==2026.1.15\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mrequests\u001B[0m\u001B[2m==2.32.5\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mrich\u001B[0m\u001B[2m==13.9.4\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mrich-click\u001B[0m\u001B[2m==1.9.7\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mscikit-learn\u001B[0m\u001B[2m==1.7.2\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mscipy\u001B[0m\u001B[2m==1.15.3\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1msetuptools\u001B[0m\u001B[2m==81.0.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1msix\u001B[0m\u001B[2m==1.17.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1msoundfile\u001B[0m\u001B[2m==0.13.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1msoxr\u001B[0m\u001B[2m==1.0.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1msympy\u001B[0m\u001B[2m==1.14.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mthreadpoolctl\u001B[0m\u001B[2m==3.6.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mtorch\u001B[0m\u001B[2m==1.13.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mtorchmetrics\u001B[0m\u001B[2m==1.5.2\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mtqdm\u001B[0m\u001B[2m==4.67.3\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mtyping-extensions\u001B[0m\u001B[2m==4.15.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mtzlocal\u001B[0m\u001B[2m==5.3.1\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1municode-rbnf\u001B[0m\u001B[2m==2.4.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1murllib3\u001B[0m\u001B[2m==2.6.3\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mwatchdog\u001B[0m\u001B[2m==6.0.0\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1mwheel\u001B[0m\u001B[2m==0.46.3\u001B[0m\r\n",
      " \u001B[32m+\u001B[39m \u001B[1myarl\u001B[0m\u001B[2m==1.22.0\u001B[0m\r\n",
      "phoonnx[train] installed ✓\n",
      "CPU times: user 30.2 ms, sys: 14.3 ms, total: 44.5 ms\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 · Phonemizer system dependencies\n",
    "\n",
    "If you use **espeak**, the `espeak-ng` binary must be on the system.\n",
    "Other phonemizers (gruut, byt5, misaki, epitran, …) might need extra python dependencies instead."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:35:21.735854Z",
     "start_time": "2026-02-14T23:35:21.727818Z"
    }
   },
   "source": [
    "# Install espeak-ng (only needed if PHONEMIZER == \"espeak\")\n",
    "if PHONEMIZER == \"espeak\":\n",
    "    if shutil.which(\"espeak-ng\") is None:\n",
    "        if PLATFORM in (\"colab\", \"kaggle\", \"paperspace\"):\n",
    "            subprocess.check_call([\"apt-get\", \"install\", \"-y\", \"-qq\", \"espeak-ng\"])\n",
    "        else:\n",
    "            print(\"⚠  espeak-ng not found. Install it manually:\")\n",
    "            print(\"   Debian/Ubuntu : sudo apt install espeak-ng\")\n",
    "            print(\"   macOS         : brew install espeak-ng\")\n",
    "            print(\"   Windows       : download from https://github.com/espeak-ng/espeak-ng/releases\")\n",
    "    else:\n",
    "        print(\"espeak-ng already installed ✓\")\n",
    "else:\n",
    "    print(f\"Phonemizer '{PHONEMIZER}' does not need espeak-ng — skipping.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "espeak-ng already installed ✓\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 · Build monotonic alignment (Cython)\n",
    "\n",
    "VITS requires a small Cython extension for monotonic alignment search.\n",
    "This compiles it in-place."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:35:30.439310Z",
     "start_time": "2026-02-14T23:35:23.982916Z"
    }
   },
   "source": [
    "%%time\n",
    "import glob\n",
    "\n",
    "MA_DIR = os.path.join(PHOONNX_DIR, \"phoonnx_train\", \"vits\", \"monotonic_align\")\n",
    "MA_OUT = os.path.join(MA_DIR, \"monotonic_align\")\n",
    "os.makedirs(MA_OUT, exist_ok=True)\n",
    "\n",
    "env = os.environ.copy()\n",
    "\n",
    "subprocess.check_call([\"cythonize\", \"-i\", \"core.pyx\"], cwd=MA_DIR, env=env)\n",
    "\n",
    "# Move compiled .so into sub-package\n",
    "for so in glob.glob(os.path.join(MA_DIR, \"core*.so\")):\n",
    "    shutil.copy2(so, MA_OUT)\n",
    "\n",
    "print(\"Monotonic alignment built ✓\")\n",
    "print(\"Contents:\", os.listdir(MA_OUT))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monotonic alignment built ✓\n",
      "Contents: ['core.cpython-310-x86_64-linux-gnu.so']\n",
      "CPU times: user 3.86 ms, sys: 88 μs, total: 3.95 ms\n",
      "Wall time: 6.45 s\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 · Download dataset & base checkpoint\n",
    "\n",
    "Downloads your dataset from Hugging Face and (optionally) a pre-trained\n",
    "checkpoint to fine-tune from.\n",
    "\n",
    "> **Storage tip**: Synthetic TTS datasets from TigreGotico are typically 30–300 MB.\n",
    "> If you already uploaded a dataset to the platform (e.g. as a Kaggle dataset),\n",
    "> set `HF_DATASET = \"\"` above and point `DATASET_DIR` to the upload location."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:20:12.240572Z",
     "start_time": "2026-02-14T23:20:12.234440Z"
    }
   },
   "source": [
    "%%time\n",
    "# ── Download dataset from Hugging Face ──────────────────────────────\n",
    "if HF_DATASET:\n",
    "    hf_cmd = [\"huggingface-cli\", \"download\", HF_DATASET,\n",
    "              \"--quiet\", \"--repo-type\", \"dataset\",\n",
    "              \"--local-dir\", DATASET_DIR]\n",
    "    if HF_TOKEN:\n",
    "        hf_cmd += [\"--token\", HF_TOKEN]\n",
    "    subprocess.check_call(hf_cmd)\n",
    "    print(f\"Dataset downloaded to {DATASET_DIR} ✓\")\n",
    "else:\n",
    "    print(f\"HF_DATASET is empty — expecting data already at {DATASET_DIR}\")\n",
    "\n",
    "# Quick sanity check\n",
    "metadata = os.path.join(DATASET_DIR, \"metadata.csv\")\n",
    "if os.path.isfile(metadata):\n",
    "    with open(metadata) as f:\n",
    "        n_lines = sum(1 for _ in f) - 1  # minus header\n",
    "    print(f\"  Found metadata.csv with {n_lines} utterances\")\n",
    "    wavs_dir = os.path.join(DATASET_DIR, \"wavs\")\n",
    "    if os.path.isdir(wavs_dir):\n",
    "        n_wavs = len([f for f in os.listdir(wavs_dir) if f.endswith(\".wav\")])\n",
    "        print(f\"  Found {n_wavs} wav files in wavs/\")\n",
    "else:\n",
    "    print(\"  ⚠  metadata.csv not found — verify your dataset path!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_DATASET is empty — expecting data already at /home/miro/phoonnx_work/dataset\n",
      "  Found metadata.csv with 1348 utterances\n",
      "CPU times: user 2.53 ms, sys: 0 ns, total: 2.53 ms\n",
      "Wall time: 1.66 ms\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:20:58.248267Z",
     "start_time": "2026-02-14T23:20:22.689418Z"
    }
   },
   "source": [
    "%%time\n",
    "# ── Download base checkpoint (for fine-tuning) ──────────────────────\n",
    "if BASE_CKPT_URL:\n",
    "    if not os.path.isfile(LOCAL_CKPT):\n",
    "        subprocess.check_call([\"wget\", \"-q\", BASE_CKPT_URL, \"-O\", LOCAL_CKPT])\n",
    "        print(f\"Checkpoint downloaded → {LOCAL_CKPT} ✓\")\n",
    "    else:\n",
    "        print(\"Checkpoint already exists — skipping download.\")\n",
    "else:\n",
    "    print(\"No base checkpoint URL — training from scratch.\")\n",
    "\n",
    "if BASE_CONFIG_URL:\n",
    "    if not os.path.isfile(LOCAL_CONFIG):\n",
    "        subprocess.check_call([\"wget\", \"-q\", BASE_CONFIG_URL, \"-O\", LOCAL_CONFIG])\n",
    "        print(f\"Config downloaded → {LOCAL_CONFIG} ✓\")\n",
    "    else:\n",
    "        print(\"Config already exists — skipping download.\")\n",
    "else:\n",
    "    print(\"No base config URL provided.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint downloaded → /home/miro/phoonnx_work/checkpoints/base.ckpt ✓\n",
      "Config downloaded → /home/miro/phoonnx_work/checkpoints/base.ckpt.json ✓\n",
      "CPU times: user 4.26 ms, sys: 2.31 ms, total: 6.57 ms\n",
      "Wall time: 35.6 s\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4 · Preprocess (phonemize + cache audio)\n",
    "\n",
    "Converts raw text → phoneme IDs and normalizes/caches audio at `SAMPLE_RATE`.\n",
    "\n",
    "**What happens under the hood:**\n",
    "1. **Text normalization** — numbers, dates, units, contractions → spoken form (language-aware)\n",
    "2. **Phonemization** — text → phoneme sequence via the chosen backend\n",
    "3. **Audio caching** — resamples wavs and computes spectrograms\n",
    "\n",
    "Outputs `config.json` + `dataset.jsonl` + `cache/` into `PREPROCESSED_DIR`.\n",
    "\n",
    "> **Skip this cell** if you already have preprocessed data (e.g. uploaded to the platform)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:23:50.116319Z",
     "start_time": "2026-02-14T23:21:11.442499Z"
    }
   },
   "source": [
    "%%time\n",
    "PREPROCESS_SCRIPT = os.path.join(PHOONNX_DIR, \"phoonnx_train\", \"preprocess.py\")\n",
    "\n",
    "cmd = [\n",
    "    VENV_PYTHON, PREPROCESS_SCRIPT,\n",
    "    \"--input-dir\",    DATASET_DIR,\n",
    "    \"--output-dir\",   PREPROCESSED_DIR,\n",
    "    \"--language\",     LANG,\n",
    "    \"--sample-rate\",  str(SAMPLE_RATE),\n",
    "    \"--phoneme-type\", PHONEMIZER,\n",
    "    \"--alphabet\",     ALPHABET,\n",
    "]\n",
    "\n",
    "# Fine-tuning: reuse previous phoneme_id_map\n",
    "if BASE_CONFIG_URL and os.path.isfile(LOCAL_CONFIG):\n",
    "    cmd += [\"--prev-config\", LOCAL_CONFIG]\n",
    "\n",
    "if SINGLE_SPEAKER:\n",
    "    cmd += [\"--single-speaker\"]\n",
    "\n",
    "if ADD_DIACRITICS:\n",
    "    cmd += [\"--add-diacritics\"]\n",
    "\n",
    "if BYT5_MODEL:\n",
    "    cmd += [\"--phonemizer-model\", BYT5_MODEL]\n",
    "\n",
    "print(\"Running:\", \" \".join(cmd))\n",
    "subprocess.check_call(cmd)\n",
    "\n",
    "# Verify outputs\n",
    "for expected in [\"config.json\", \"dataset.jsonl\"]:\n",
    "    path = os.path.join(PREPROCESSED_DIR, expected)\n",
    "    if os.path.isfile(path):\n",
    "        size_mb = os.path.getsize(path) / 1e6\n",
    "        print(f\"  ✓ {expected}  ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"  ✗ {expected}  MISSING — check logs above\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: /home/miro/phoonnx_work/.venv/bin/python /home/miro/phoonnx_work/phoonnx/phoonnx_train/preprocess.py --input-dir /home/miro/phoonnx_work/dataset --output-dir /home/miro/phoonnx_work/training --language pt --sample-rate 22050 --phoneme-type espeak --alphabet ipa --prev-config /home/miro/phoonnx_work/checkpoints/base.ckpt.json --single-speaker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocess:Loading utterances from dataset...\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000015\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000016\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000017\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000018\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000019\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000020\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000021\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000023\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000024\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000025\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000026\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000027\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000028\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000029\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000030\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000031\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000032\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000033\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000034\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000035\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000036\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000037\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000038\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000039\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000040\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000041\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000042\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000043\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000044\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000045\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000046\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000047\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000048\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000049\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000050\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000051\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000052\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000053\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000054\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000055\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000056\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000057\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000058\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000059\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000060\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000061\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000062\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000063\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000064\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000065\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000066\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000067\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000068\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000069\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000070\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000071\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000072\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000073\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000074\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000075\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000076\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000077\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000078\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000079\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000080\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000081\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000082\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000083\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000084\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000085\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000086\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000087\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000088\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000089\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000090\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000091\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000092\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000093\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000094\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000095\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000096\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000097\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000098\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000099\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000100\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000101\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000102\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000103\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000104\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000105\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000106\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000107\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000108\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000109\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000110\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000111\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000112\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000113\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000114\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000115\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000116\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000117\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000118\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000119\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000120\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000121\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000122\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000123\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000124\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000125\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000126\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000127\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000128\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000129\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000130\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000131\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000132\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000133\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000134\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000135\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000136\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000137\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000138\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000139\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000140\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000141\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000142\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000143\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000144\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000145\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000146\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000147\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000148\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000149\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000150\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000151\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000152\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000153\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000154\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000155\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000156\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000157\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000158\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000159\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000160\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000161\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000162\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000163\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000164\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000165\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000166\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000167\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000168\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000169\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000170\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000171\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000172\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000173\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000174\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000175\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000176\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000177\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000178\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000179\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000180\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000181\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000182\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000183\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000184\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000185\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000186\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000187\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000188\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000189\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000190\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000191\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000192\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000193\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000194\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000195\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000196\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000197\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000198\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000199\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000200\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000201\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000202\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000203\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000204\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000205\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000206\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000207\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000208\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000209\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000210\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000211\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000212\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000213\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000214\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000215\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000216\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000217\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000218\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000219\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000220\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000221\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000222\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000223\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000224\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000225\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000226\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000227\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000228\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000229\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000230\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000231\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000232\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000233\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000234\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000235\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000236\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000237\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000238\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000239\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000240\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000241\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000242\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000243\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000244\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000245\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000246\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000247\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000248\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000249\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000250\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000251\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000252\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000253\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000254\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000255\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000256\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000257\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000258\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000259\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000260\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000261\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000262\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000263\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000264\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000265\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000266\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000267\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000268\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000269\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000270\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000271\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000272\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000273\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000274\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000275\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000276\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000277\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000278\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000279\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000280\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000281\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000282\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000283\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000284\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000285\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000286\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000287\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000288\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000289\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000290\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000291\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000292\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000293\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000294\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000295\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000296\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000297\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000298\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000299\n",
      "WARNING:preprocess:Missing audio file for filename: 4000000300\n",
      "WARNING:preprocess:Missing audio file for filename: 6660000001\n",
      "WARNING:preprocess:Missing audio file for filename: 6660000002\n",
      "WARNING:preprocess:Missing audio file for filename: 6660000003\n",
      "WARNING:preprocess:Missing audio file for filename: 6660000004\n",
      "WARNING:preprocess:Missing audio file for filename: 6660000005\n",
      "WARNING:preprocess:Missing audio file for filename: 6660000006\n",
      "WARNING:preprocess:Missing audio file for filename: 5\n",
      "WARNING:preprocess:Missing audio file for filename: 7\n",
      "WARNING:preprocess:Missing audio file for filename: 8\n",
      "WARNING:preprocess:Missing audio file for filename: 41\n",
      "WARNING:preprocess:Missing audio file for filename: 42\n",
      "WARNING:preprocess:Missing audio file for filename: 43\n",
      "WARNING:preprocess:Missing audio file for filename: 45\n",
      "WARNING:preprocess:Missing audio file for filename: 47\n",
      "WARNING:preprocess:Missing audio file for filename: 48\n",
      "WARNING:preprocess:Missing audio file for filename: 50\n",
      "WARNING:preprocess:Missing audio file for filename: 51\n",
      "WARNING:preprocess:Missing audio file for filename: 52\n",
      "WARNING:preprocess:Missing audio file for filename: 53\n",
      "WARNING:preprocess:Missing audio file for filename: 54\n",
      "WARNING:preprocess:Missing audio file for filename: 55\n",
      "WARNING:preprocess:Missing audio file for filename: 56\n",
      "WARNING:preprocess:Missing audio file for filename: 57\n",
      "WARNING:preprocess:Missing audio file for filename: 58\n",
      "WARNING:preprocess:Missing audio file for filename: 59\n",
      "WARNING:preprocess:Missing audio file for filename: 60\n",
      "WARNING:preprocess:Missing audio file for filename: 61\n",
      "WARNING:preprocess:Missing audio file for filename: 62\n",
      "WARNING:preprocess:Missing audio file for filename: 63\n",
      "WARNING:preprocess:Missing audio file for filename: 64\n",
      "WARNING:preprocess:Missing audio file for filename: 65\n",
      "WARNING:preprocess:Missing audio file for filename: 66\n",
      "WARNING:preprocess:Missing audio file for filename: 67\n",
      "WARNING:preprocess:Missing audio file for filename: 68\n",
      "WARNING:preprocess:Missing audio file for filename: 69\n",
      "WARNING:preprocess:Missing audio file for filename: 70\n",
      "WARNING:preprocess:Missing audio file for filename: 71\n",
      "WARNING:preprocess:Missing audio file for filename: 72\n",
      "WARNING:preprocess:Missing audio file for filename: 73\n",
      "WARNING:preprocess:Missing audio file for filename: 75\n",
      "WARNING:preprocess:Missing audio file for filename: 76\n",
      "WARNING:preprocess:Missing audio file for filename: 77\n",
      "WARNING:preprocess:Missing audio file for filename: 78\n",
      "WARNING:preprocess:Missing audio file for filename: 79\n",
      "WARNING:preprocess:Missing audio file for filename: 80\n",
      "WARNING:preprocess:Missing audio file for filename: 81\n",
      "WARNING:preprocess:Missing audio file for filename: 82\n",
      "WARNING:preprocess:Missing audio file for filename: 83\n",
      "WARNING:preprocess:Missing audio file for filename: 84\n",
      "WARNING:preprocess:Missing audio file for filename: 85\n",
      "WARNING:preprocess:Missing audio file for filename: 86\n",
      "WARNING:preprocess:Missing audio file for filename: 87\n",
      "WARNING:preprocess:Missing audio file for filename: 88\n",
      "WARNING:preprocess:Missing audio file for filename: 89\n",
      "WARNING:preprocess:Missing audio file for filename: 90\n",
      "WARNING:preprocess:Missing audio file for filename: 91\n",
      "WARNING:preprocess:Missing audio file for filename: 92\n",
      "WARNING:preprocess:Missing audio file for filename: 93\n",
      "WARNING:preprocess:Missing audio file for filename: 94\n",
      "WARNING:preprocess:Missing audio file for filename: 95\n",
      "WARNING:preprocess:Missing audio file for filename: 96\n",
      "WARNING:preprocess:Missing audio file for filename: 97\n",
      "WARNING:preprocess:Missing audio file for filename: 98\n",
      "WARNING:preprocess:Missing audio file for filename: 99\n",
      "INFO:preprocess:Found 1000 utterances.\n",
      "INFO:preprocess:Single speaker dataset\n",
      "INFO:preprocess:Starting single pass processing with 16 workers...\n",
      "Processing utterances:  77%|███████▋  | 774/1000 [02:08<00:20, 11.02it/s]ERROR:preprocess:Failed to process utterance: /home/miro/phoonnx_work/dataset/wav/0300000031.wav\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miro/phoonnx_work/phoonnx/phoonnx_train/preprocess.py\", line 213, in phonemize_worker\n",
      "    utterance: str = casing(normalize(utt.text, config.language))\n",
      "  File \"/home/miro/phoonnx_work/phoonnx/phoonnx/util.py\", line 725, in normalize\n",
      "    dialog = _normalize_units(dialog, full_lang)\n",
      "  File \"/home/miro/phoonnx_work/phoonnx/phoonnx/util.py\", line 662, in _normalize_units\n",
      "    text = alphanumeric_pattern.sub(replace_alphanumeric, text)\n",
      "  File \"/home/miro/phoonnx_work/phoonnx/phoonnx/util.py\", line 659, in replace_alphanumeric\n",
      "    unit_word = alphanumeric_units[unit_symbol]\n",
      "KeyError: 'S'\n",
      "Processing utterances: 100%|██████████| 1000/1000 [02:32<00:00,  6.55it/s]\n",
      "INFO:preprocess:Building a phoneme map from collected dataset phonemes...\n",
      "INFO:preprocess:Loaded phoneme map from previous config: '/home/miro/phoonnx_work/checkpoints/base.ckpt.json'\n",
      "INFO:preprocess:previous phoneme map contains 159 phonemes.\n",
      "INFO:preprocess:Collected 0 new phonemes.\n",
      "INFO:preprocess:Writing dataset config...\n",
      "INFO:preprocess:Writing dataset.jsonl...\n",
      "INFO:preprocess:Preprocessing complete. Wrote 999 valid utterances to dataset.jsonl.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ config.json  (0.0 MB)\n",
      "  ✓ dataset.jsonl  (1.3 MB)\n",
      "CPU times: user 470 ms, sys: 115 ms, total: 585 ms\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5 · Train\n",
    "\n",
    "Launches VITS training with PyTorch Lightning. Checkpoints are saved every epoch\n",
    "to `CHECKPOINTS_DIR`.\n",
    "\n",
    "**Tips for constrained environments:**\n",
    "- Reduce `BATCH_SIZE` to 8 or 4 if you get OOM errors\n",
    "- Use `PRECISION = 16` (mixed precision) to cut VRAM by ~40%\n",
    "- Free-tier Kaggle/Colab may time-out after 9–12 h — the model will resume from the last checkpoint\n",
    "- Set `MAX_EPOCHS` conservatively and re-run to continue\n",
    "\n",
    "> Training is the longest step. On a single T4 GPU with batch size 16, expect ~2 min/epoch\n",
    "> for a dataset of ~1000 utterances."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2026-02-14T23:31:39.882860849Z",
     "start_time": "2026-02-14T23:29:39.709895Z"
    }
   },
   "source": [
    "%%time\n",
    "TRAIN_SCRIPT = os.path.join(PHOONNX_DIR, \"phoonnx_train\", \"train.py\")\n",
    "\n",
    "cmd = [\n",
    "    VENV_PYTHON, TRAIN_SCRIPT,\n",
    "    \"--dataset-dir\",      PREPROCESSED_DIR,\n",
    "    \"--accelerator\",      ACCELERATOR,\n",
    "    \"--devices\",          \"1\",\n",
    "    \"--batch-size\",       str(BATCH_SIZE),\n",
    "    \"--validation-split\", str(VALIDATION_SPLIT),\n",
    "    \"--max-epochs\",       str(MAX_EPOCHS),\n",
    "    \"--checkpoint-epochs\", \"1\",\n",
    "    \"--precision\",        str(PRECISION),\n",
    "    \"--quality\",          QUALITY,\n",
    "    \"--learning-rate\",    str(LEARNING_RATE),\n",
    "    \"--default-root-dir\", CHECKPOINTS_DIR,\n",
    "]\n",
    "\n",
    "# Resume from base checkpoint (fine-tuning)\n",
    "if BASE_CKPT_URL and os.path.isfile(LOCAL_CKPT):\n",
    "    cmd += [\"--resume-from-checkpoint\", LOCAL_CKPT]\n",
    "\n",
    "print(\"Running:\", \" \".join(cmd))\n",
    "print(\"─\" * 60)\n",
    "subprocess.check_call(cmd)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: /home/miro/phoonnx_work/.venv/bin/python /home/miro/phoonnx_work/phoonnx/phoonnx_train/train.py --dataset-dir /home/miro/phoonnx_work/training --accelerator gpu --devices 1 --batch-size 16 --validation-split 0.05 --max-epochs 2 --checkpoint-epochs 1 --precision 32 --quality medium --learning-rate 0.0002 --default-root-dir /home/miro/phoonnx_work/checkpoints --resume-from-checkpoint /home/miro/phoonnx_work/checkpoints/base.ckpt\n",
      "────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miro/phoonnx_work/.venv/lib/python3.10/site-packages/lightning_fabric/__init__.py:29: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "INFO:root:config_path: '/home/miro/phoonnx_work/training/config.json'\n",
      "INFO:root:dataset_path: '/home/miro/phoonnx_work/training/dataset.jsonl'\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/miro/phoonnx_work/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "INFO:root:Checkpoints will be saved every 1 epoch(s)\n",
      "DEBUG:root:Config params: num_symbols=256 num_speakers=1 sample_rate=22050\n",
      "DEBUG:fsspec.local:open file: /home/miro/phoonnx_work/checkpoints/base.ckpt\n",
      "DEBUG:vits.lightning:No dataset to load\n",
      "DEBUG:root:Checkpoint params: num_symbols=256 num_speakers=1 sample_rate=22050\n",
      "DEBUG:vits.dataset:Loading dataset: /home/miro/phoonnx_work/training/dataset.jsonl\n",
      "INFO:root:VitsModel params: num_symbols=256 num_speakers=1 sample_rate=22050\n",
      "INFO:root:Successfully loaded model weights.\n",
      "INFO:root:training started!!\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/miro/phoonnx_work/checkpoints/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "DEBUG:fsspec.local:open file: /home/miro/phoonnx_work/checkpoints/lightning_logs/version_0/hparams.yaml\n",
      "/home/miro/phoonnx_work/.venv/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:83: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "DEBUG:fsspec.local:open file: /home/miro/phoonnx_work/checkpoints/lightning_logs/version_0/hparams.yaml\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6 · Export to ONNX\n",
    "\n",
    "Converts the best `.ckpt` to ONNX format for fast, cross-platform inference.\n",
    "\n",
    "The exported model works with:\n",
    "- **phoonnx** (Python inference)\n",
    "- **Piper TTS** (if trained with espeak + IPA)\n",
    "- **sherpa-onnx** (C++/mobile, with `--generate-tokens`)\n",
    "- **Open Voice OS** (OVOS TTS plugin)\n",
    "- **NVDA screen reader** ([phoonnx-AddonNVDA](https://github.com/TigreGotico/phoonnx-AddonNVDA))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:35:54.456608Z",
     "start_time": "2026-02-14T23:35:37.174975Z"
    }
   },
   "source": [
    "%%time\n",
    "import glob, os\n",
    "\n",
    "EXPORT_SCRIPT = os.path.join(PHOONNX_DIR, \"phoonnx_train\", \"export_onnx.py\")\n",
    "TRAIN_CONFIG  = os.path.join(PREPROCESSED_DIR, \"config.json\")\n",
    "\n",
    "# Find the latest checkpoint\n",
    "ckpt_pattern = os.path.join(CHECKPOINTS_DIR, \"**\", \"*.ckpt\")\n",
    "ckpts = sorted(glob.glob(ckpt_pattern, recursive=True), key=os.path.getmtime)\n",
    "\n",
    "if not ckpts:\n",
    "    print(\"✗ No checkpoints found — run training first.\")\n",
    "else:\n",
    "    best_ckpt = ckpts[-1]\n",
    "    print(f\"Exporting: {best_ckpt}\")\n",
    "\n",
    "    cmd = [\n",
    "        VENV_PYTHON, EXPORT_SCRIPT,\n",
    "        best_ckpt,\n",
    "        \"--config\",     TRAIN_CONFIG,\n",
    "        \"--output-dir\", EXPORT_DIR,\n",
    "        \"--generate-tokens\",   # for sherpa-onnx compatibility\n",
    "        \"--piper\",             # for Piper TTS compatibility\n",
    "    ]\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "    print(f\"\\nExported files in {EXPORT_DIR}:\")\n",
    "    for f in sorted(os.listdir(EXPORT_DIR)):\n",
    "        size = os.path.getsize(os.path.join(EXPORT_DIR, f)) / 1e6\n",
    "        print(f\"  {f}  ({size:.1f} MB)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting: /home/miro/phoonnx_work/checkpoints/base.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miro/phoonnx_work/.venv/lib/python3.10/site-packages/lightning_fabric/__init__.py:29: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "DEBUG:phoonnx_train.export_onnx:Arguments: checkpoint=PosixPath('/home/miro/phoonnx_work/checkpoints/base.ckpt'), config=PosixPath('/home/miro/phoonnx_work/training/config.json'), output_dir=PosixPath('/home/miro/phoonnx_work/exported'), generate_tokens=True, piper=True\n",
      "DEBUG:phoonnx_train.export_onnx:Output directory ensured: /home/miro/phoonnx_work/exported\n",
      "INFO:phoonnx_train.export_onnx:Loaded phoonnx config from /home/miro/phoonnx_work/training/config.json\n",
      "INFO:phoonnx_train.export_onnx:Generated tokens file at /home/miro/phoonnx_work/exported/base.ckpt.tokens.txt\n",
      "DEBUG:fsspec.local:open file: /home/miro/phoonnx_work/checkpoints/base.ckpt\n",
      "DEBUG:vits.lightning:No dataset to load\n",
      "DEBUG:phoonnx_train.export_onnx:Removed weight normalization from decoder.\n",
      "INFO:phoonnx_train.export_onnx:Starting ONNX export to /home/miro/phoonnx_work/exported/base.ckpt.onnx (opset=15)...\n",
      "/home/miro/phoonnx_work/phoonnx/phoonnx_train/vits/attentions.py:235: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  t_s == t_t\n",
      "/home/miro/phoonnx_work/phoonnx/phoonnx_train/vits/attentions.py:295: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  pad_length = max(length - (self.window_size + 1), 0)\n",
      "/home/miro/phoonnx_work/phoonnx/phoonnx_train/vits/attentions.py:296: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  slice_start_position = max((self.window_size + 1) - length, 0)\n",
      "/home/miro/phoonnx_work/phoonnx/phoonnx_train/vits/attentions.py:298: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_length > 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing weight norm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miro/phoonnx_work/phoonnx/phoonnx_train/vits/transforms.py:174: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert (discriminant >= 0).all(), discriminant\n",
      "/home/miro/phoonnx_work/.venv/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/miro/phoonnx_work/.venv/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/miro/phoonnx_work/.venv/lib/python3.10/site-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/miro/phoonnx_work/.venv/lib/python3.10/site-packages/torch/onnx/utils.py:687: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/miro/phoonnx_work/.venv/lib/python3.10/site-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/miro/phoonnx_work/.venv/lib/python3.10/site-packages/torch/onnx/utils.py:1178: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "INFO:phoonnx_train.export_onnx:Successfully exported model to /home/miro/phoonnx_work/exported/base.ckpt.onnx\n",
      "ERROR:phoonnx_train.export_onnx:The 'onnx' package is required to add metadata. Please install it with 'pip install onnx'.\n",
      "INFO:phoonnx_train.export_onnx:Export complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exported files in /home/miro/phoonnx_work/exported:\n",
      "  base.ckpt.onnx  (63.5 MB)\n",
      "  base.ckpt.piper.json  (0.0 MB)\n",
      "  base.ckpt.tokens.txt  (0.0 MB)\n",
      "CPU times: user 11.8 ms, sys: 10.8 ms, total: 22.6 ms\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7 · Quick inference test (optional)\n",
    "\n",
    "Synthesizes a short sentence with the exported ONNX model to verify everything works."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:36:05.464945Z",
     "start_time": "2026-02-14T23:36:03.494955Z"
    }
   },
   "source": [
    "import glob, os\n",
    "\n",
    "onnx_files = glob.glob(os.path.join(EXPORT_DIR, \"*.onnx\"))\n",
    "json_files = glob.glob(os.path.join(EXPORT_DIR, \"*.json\"))\n",
    "\n",
    "if onnx_files and json_files:\n",
    "    onnx_path = onnx_files[0]\n",
    "    json_path = json_files[0]\n",
    "    test_wav  = os.path.join(EXPORT_DIR, \"test_output.wav\")\n",
    "\n",
    "    test_code = f'''\n",
    "import wave\n",
    "from phoonnx.config import SynthesisConfig\n",
    "from phoonnx.voice import TTSVoice\n",
    "\n",
    "voice = TTSVoice.load(\"{onnx_path}\", \"{json_path}\")\n",
    "config = SynthesisConfig(noise_scale=0.667, length_scale=1.0, noise_w_scale=0.8)\n",
    "with wave.open(\"{test_wav}\", \"wb\") as wf:\n",
    "    voice.synthesize_wav(\"Hello, this is a test.\", wf, config)\n",
    "print(\"Inference test passed ✓  →  {test_wav}\")\n",
    "'''\n",
    "    # Write & run with the training Python (which has phoonnx installed)\n",
    "    test_script = os.path.join(WORK, \"_test_inference.py\")\n",
    "    with open(test_script, \"w\") as f:\n",
    "        f.write(test_code)\n",
    "    subprocess.check_call([VENV_PYTHON, test_script])\n",
    "else:\n",
    "    print(\"No exported model found — run the export cell first.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference test passed ✓  →  /home/miro/phoonnx_work/exported/test_output.wav\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8 · Cleanup (optional)\n",
    "\n",
    "Free disk space by removing intermediate files. Only the exported ONNX model and\n",
    "the latest checkpoint are kept."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T23:36:52.309802Z",
     "start_time": "2026-02-14T23:36:52.306921Z"
    }
   },
   "source": [
    "# Uncomment the lines below to reclaim disk space\n",
    "\n",
    "# Remove cached spectrograms (largest intermediate artifact)\n",
    "# shutil.rmtree(os.path.join(PREPROCESSED_DIR, \"cache\"), ignore_errors=True)\n",
    "\n",
    "# Remove the cloned phoonnx repo\n",
    "# shutil.rmtree(PHOONNX_DIR, ignore_errors=True)\n",
    "\n",
    "# Remove the raw dataset (keep only preprocessed + exported)\n",
    "# shutil.rmtree(DATASET_DIR, ignore_errors=True)\n",
    "\n",
    "print(\"Cleanup section — uncomment lines above to free disk space.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup section — uncomment lines above to free disk space.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix A · Dataset format (LJSpeech-style)\n",
    "\n",
    "phoonnx expects an **LJSpeech-style** directory:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├── metadata.csv       # pipe-separated: filename|text  (no header)\n",
    "└── wavs/\n",
    "    ├── 0001.wav\n",
    "    ├── 0002.wav\n",
    "    └── ...\n",
    "```\n",
    "\n",
    "- Audio should be **mono WAV** at the target sample rate (default 22050 Hz)\n",
    "- For multi-speaker datasets, add a third column: `filename|speaker_id|text`\n",
    "\n",
    "### Available synthetic datasets\n",
    "\n",
    "Browse ready-to-use datasets at:\n",
    "**[huggingface.co/collections/TigreGotico/synthetic-tts-datasets](https://huggingface.co/collections/TigreGotico/synthetic-tts-datasets)**\n",
    "\n",
    "Languages include: Arabic, Asturian, Aragonese, Basque, Catalan (4 dialects), Colombian Spanish,\n",
    "Danish, Dutch, English (US/GB), Farsi, French, Galician, German, Hebrew, Hindi, Italian,\n",
    "Japanese, Korean, Marwari, Mirandese, Polish, Portuguese (PT/BR), Romanian, Spanish, Swedish, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix B · Understanding `config.json`\n",
    "\n",
    "The preprocessing step produces a `config.json` that stores model + dataset parameters:\n",
    "\n",
    "| Field | Description |\n",
    "|---|---|\n",
    "| `audio.sample_rate` | Training/inference sample rate (e.g. 22050) |\n",
    "| `audio.quality` | Label from `--quality` flag or output folder name |\n",
    "| `lang_code` | Language code used for phonemization (normalized via `langcodes`) |\n",
    "| `inference.noise_scale` | Controls variability in speech (default 0.667) |\n",
    "| `inference.length_scale` | Controls speech rate (1.0 = normal) |\n",
    "| `inference.noise_w` | Additional noise parameter (default 0.8) |\n",
    "| `inference.add_diacritics` | Arabic tashkeel / Hebrew nikud (default false) |\n",
    "| `alphabet` | Phoneme alphabet: `ipa`, `arpa`, `pinyin`, … |\n",
    "| `phoneme_type` | Which phonemizer was used |\n",
    "| `phonemizer_model` | Only for ByT5-based phonemizers |\n",
    "| `phoneme_id_map` | Symbol → numeric ID mapping |\n",
    "| `num_speakers` | 1 for single-speaker, >1 for multi-speaker |\n",
    "| `speaker_id_map` | Speaker label → ID (multi-speaker only) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix C · Troubleshooting\n",
    "\n",
    "| Problem | Solution |\n",
    "|---|---|\n",
    "| **OOM (Out of Memory)** | Lower `BATCH_SIZE` to 8 or 4, or set `PRECISION = 16` |\n",
    "| **Session timeout** | Re-run the training cell — it resumes from last checkpoint |\n",
    "| **espeak-ng not found** | Run the system-deps cell, or install manually |\n",
    "| **Cython build fails** | Ensure `cython` is installed: `pip install cython` |\n",
    "| **Dataset not found** | Check `DATASET_DIR` path and verify `metadata.csv` exists |\n",
    "| **phoneme_id_map mismatch** | When fine-tuning, always pass `--prev-config` |\n",
    "| **Slow training on CPU** | Use a GPU runtime — CPU is not practical for VITS |\n",
    "| **Python version issues** | phoonnx train works best with Python ≤3.10 |"
   ]
  }
 ]
}
